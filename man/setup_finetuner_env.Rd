% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/finetuner.R
\name{setup_finetuner_env}
\alias{setup_finetuner_env}
\title{Setup the Python Environment for finetuneR}
\usage{
setup_finetuner_env(
  packages = c("transformers", "datasets", "torch", "pandas", "numpy", "accelerate",
    "scikit-learn"),
  num_threads = 1L,
  parallel_tokenizers = FALSE,
  global_seed = 11L
)
}
\arguments{
\item{packages}{A character vector of Python packages to install.}

\item{num_threads}{An integer specifying the number of threads for libraries
like PyTorch and MKL. Defaults to `1`.}

\item{parallel_tokenizers}{A logical value. If `FALSE` (the default), it
disables parallelism for Hugging Face tokenizers, which can prevent
deadlocks. Set to `TRUE` to enable it if your environment supports it.}

\item{global_seed}{An integer to set the master seed for `numpy` and `torch`
for global reproducibility. Defaults to `11`.}
}
\description{
Installs necessary Python packages, imports key libraries, and configures
environment variables for parallelism and reproducibility.
}
