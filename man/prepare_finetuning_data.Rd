% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/finetuner.R
\name{prepare_finetuning_data}
\alias{prepare_finetuning_data}
\title{Prepare Datasets for Fine-Tuning}
\usage{
prepare_finetuning_data(
  df,
  task_type = "classification",
  text_col = "text",
  label_col = "label",
  model_name,
  test_split_ratio = 0.2,
  val_split_ratio = 0.2,
  max_length = 512L,
  seed = 42,
  stratified = FALSE
)
}
\arguments{
\item{df}{A dataframe containing the text and labels.}

\item{task_type}{A string, either `"classification"` or `"regression"`.}

\item{text_col}{The name of the column with the text data.}

\item{label_col}{The name of the column with the label data.}

\item{model_name}{The name of the pre-trained model from Hugging Face Hub.}

\item{test_split_ratio}{The proportion of the data to use for the test set.}

\item{val_split_ratio}{The proportion of the *training* data to use for the
validation set.}

\item{max_length}{The maximum sequence length for the tokenizer.}

\item{seed}{An integer for the random seed for reproducibility of the data split.}

\item{stratified}{A logical value. If `TRUE`, performs stratified sampling
for classification tasks to maintain label distribution. Defaults to `FALSE`.}
}
\value{
A list containing the `train`, `validation`, and `test` PyTorch datasets.
}
\description{
This function takes a dataframe, splits it into training, validation,
and testing sets, tokenizes the text, and wraps the
results in Python-compatible Dataset objects ready for the Trainer.
}
